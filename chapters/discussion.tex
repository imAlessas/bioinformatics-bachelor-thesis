%!TEX root = ../main.tex

\chapter{Discussione}\label{chp:discussion}
% 
Dopo aver dettagliatamente descritto le caratteristiche dei tre strumenti bioinformatici nel Capitolo\,\ref{chp:CNN-non-coding-variants}, in questo capitolo si paragoneranno i tre tool, sottolineando le proprietà comuni e gli aspetti per cui differiscono in modo da fornire un confronto oggettivo che permette di comprendere in maniera più approfondita le loro performance predittive.

DeepSEA, Basset e DeepSATA, hanno alcune caratteristiche in comune. I tre tool utilizzano lo stesso metodo di codifica della sequenza, il One-Hot encoding, che rende la sequenza luna $M$ in una matrice $M\times 4$, mappando le basi azotate della sequenza in vettori. In questo modo la sequenza può essere processata correttamente dai kernel, che sono delle \acs{PWM} che associano a ciascuna base delle sequenza un peso (o probabilità di occorrenza) in una particolare posizione (Figura\,\ref{fig:PWM}). Infine i tre modelli sono stati allenati attraverso il \acs{SGD} cercando di ottimizzare la stessa funzione obiettivo (cost function): la binary cross entropy (\acs{BCE}).

\vspace{5px}

Nonostante le similarità descritte, i tre strumenti presentano diverse differenze, soprattutto nella struttura della rete e nel training dataset scelto: la Tabella\,\ref{tab:summary} riassume le caratteristiche principali. \,\hyperref[sec:DeepSEA]{\textsl{DeepSEA}} è composto da tre livelli convoluzionali, ciascuno dei quali viene seguito sempre da un livello \acs{ReLU} e da un livello max-pooling, utilizzato per estrarre le feature dominanti processate dalla convoluzione. I tre livelli convoluzionali contengono rispettivamente 320, 480 e 960 filtri. In seguito è presente un fully-conncted layer che prepara la informazioni per essere valutate nell'output layer, formato da una sigmoide.

Anche \hyperref[sec:Basset]{\textsl{Basset}} è composto da tre livelli convoluzionali ma in aggiunga al \acs{ReLU} layer e al max-pooling layer viene inserito anche un livello di normalizzazione. Sono poi presenti tre livelli fully-connected che sono alternati da altri \acs{ReLU} layer e dei dropout layer, per evitare l'overfitting. Anche in questo caso l'output è calcolato tramite una sigmoide.
% 
\begin{table}[!t]
    \centering
    \caption{Riassunto delle differenze tra i tre tool.}\label{tab:summary}
    \renewcommand{\arraystretch}{2}
    \begin{tabular}{|>{\centering\arraybackslash}m{2cm}|>{\centering\arraybackslash}m{4.5cm}|>{\centering\arraybackslash}m{1.5cm}|>{\centering\arraybackslash}m{1.5cm}|>{\centering\arraybackslash}m{3cm}|} % chktex-file 44
        \hline % chktex-file 44
        \textbf{Modello} & \textbf{Struttura} & \textbf{Kernel} & \textbf{Input} & \textbf{Dataset} \\ 
        \hline\hline % chktex-file 44
        \hyperref[sec:DeepSEA]{\textsl{DeepSEA}} & Tre livelli convoluzionali — ciascuno seguito da un \acs{ReLU} layer e da un max-pooling layer — e un fully-connected layer  &  320, 480, 960 & $1000\times 4$ & \acs{ENCODE}, Roadmap Epigenomics\\ 
        % 
        \hyperref[sec:Basset]{\textsl{Basset}} & Tre livelli convoluzionali — ciascuno seguito da un normalization layer, un \acs{ReLU} layer e da un max-pooling layer — e tre fully-connected layer — alternati da un \acs{ReLU} layer ed un dropout layer &  300, 200, 200 & $600 \times 4$ & \acs{ENCODE}, Roadmap Epigenomics\\ 
        % 
        \hyperref[sec:DeepSATA]{\textsl{DeepSATA}} & Tre livelli convoluzionali — ciascuno seguito da un \acs{ReLU} layer, da un max-pooling layer e da un dropout layer — e un fully-connected layer & 320, 480, 960 & $1000\times 4\times 11$ & \acs{ENCODE}, \acs{NCBI} \acs{SRA}, \acs{GEO}, UC Davis\\ 
        \hline
    \end{tabular}
    \renewcommand{\arraystretch}{1}
\end{table}

Come DeepSEA e Basset, anche \hyperref[sec:DeepSATA]{\textsl{DeepSATA}} è composto da tre livelli di convoluzione, con rispettivamente 320, 480 e 960 kernel. Ad ogni layer convoluzionale segue un \acs{ReLU} layer, un max-pooling layer ed un dropout layer, per prevenire il rischio di overfitting. Ai livelli convoluzionali segue un fully connected layer che processa le informazioni per l'output layer che applica una funzione sigmoide. Si osserva inoltre che in questo modello, a differenza degli altri due, processa un input tridimensionale, volto a fornire più contesto per comprendere in maniera migliore gli eventuali effetti delle mutazioni sulla sequenza.

Gli autori dell'articolo che introduce DeepSATA, dopo aver illustrato il modello e le principali differenze con il suo predecessore DeepSEA, conducono un esperimento dove paragonano le capacità predittive di DeepSEA, Basset e DeepSATA.\@ In particolare, dopo aver allenato i tre modelli sul dataset contenente sequenze di specie animali diverse, tra cui l'uomo, valutano le prestazione dei modelli. Dai risultati del test (Tabella\,\ref{tab:comparison}) si nota che le prestazioni predittive di DeepSATA, anche se non di molto, superano le prestazioni di DeepSEA e di Basset. In particolare si nota una maggiore differenza nelle sequenze genetiche dei maiali, dove il valore \acs{AUC}/\acs{AUROC} è superiore di più di cinque punti percentuale. Nelle altre specie invece, anche se non di tanto, DeepSATA ottiene comunque risultati migliori.
\begin{table}[!h]
    \centering
    \caption{Risultati \acs{AUC} relativi ai confronti tra DeepSEA, Basset e DeepSATA.}\label{tab:comparison}
    \renewcommand{\arraystretch}{2}
    \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|} % chktex-file 44
        \hline % chktex-file 44
        \textbf{Modello} & \textbf{Topi} & \textbf{Maiali} & \textbf{Bovini} & \textbf{Umani} & \textbf{Polli}\\ 
        \hline\hline % chktex-file 44
        \hyperref[sec:DeepSATA]{\textsl{DeepSATA}} & 0.854 & 0.779 & 0.772 & 0.759 & 0.744 \\ 
        % 
        \hyperref[sec:DeepSEA]{\textsl{DeepSEA}} & 0.796 & 0.775 & 0.769 & 0.755 & 0.736 \\ 
        % 
        \hyperref[sec:Basset]{\textsl{Basset}} & 0.778 & 0.719 & 0.768 & 0.717 & 0.722 \\ 
        \hline
    \end{tabular}
    \renewcommand{\arraystretch}{1}
\end{table}
Dalla Tabella\,\ref{tab:comparison} si nota che i valori \acs{AUROC} di DeepSATA e DeepSEA differiscono di pochi  millesimi tra loro, a differenza dei valori di Basset, che talvolta sono nettamente più bassi rispetto ai valori degli altri due modelli. In particolare sulle sequenze che riguardano il genoma umano si nota una differenza di circa quattro punti percentuale tra Basset e DeepSEA/DeepSATA.\@
% 
\begin{figure}[!b]
    \centering
    \includegraphics[width=1\textwidth]{assets/imgs/comparison.jpg}
    \caption[Confronto delle prestazioni predittive dei tre tool su diverse specie animali.]{Confronto delle prestazioni predittive dei tre tool su diverse specie animali attraverso le curve \acs{ROC}, mostrate per ogni \acs{OCR}, e dai valori medi di \acs{AUROC}\,\cite{ma2023deepsata}.}\label{fig:comparison}
\end{figure}
% 
Di conseguenza, la tabella, oltre che ad indicare che DeepSATA abbia capacità predittive migliori rispetto agli altri due strumenti, suggerisce che il modello di DeepSEA riesce a riconoscere in maniera migliore le categorie rispetto a Basset. Le informazioni riportate sulla Tabella\,\ref{tab:comparison} sono anche rappresentate sotto forma di curve \acs{ROC} nella Figura\,\ref{fig:comparison}, dove sono indicate le performance predittive di ciascun modello a seconda delle specie animali in esame. Per ciascuna specie animale e per ciascuno dei tre tool, sono stati rappresentati i grafici delle loro prestazioni. In particolare in ciascun grafico sono presenti diverse curve \acs{ROC}, ciascuna delle quali indica la capacità predittiva rispetto ad una precisa \acs{OCR}. Per ciascuna delle curve è stato calcolato il valore \acs{AUC} e poi calcolata la media per ciascuna specie, ottenendo i valori indicati nella Tabella\,\ref{tab:comparison}.

Infine, dagli articoli emergono alcune caratteristiche computazionali dei tool. In particolare, per allenare DeepSEA è stata utilizzata la \acs{GPU} \textsl{NVIDIA Tesla K20m}, ma non viene specificato il tempo impiegato. È però disponibile una \textsl{repository GitHub} con una implementazione non ufficiale dello stesso tool, usando la libreria Python \href{https://www.tensorflow.org}{TensorFlow}. Nella descrizione di questa repository viene indicato che per allenare completamente il tool da zero con una GTX 1070 sono stati necessari circa 10 giorni\,\cite{deepseagithub}. L'articolo di Basset, invece, descrive in modo più esemplificativo le sue caratteristiche. In particolare, l'allenamento del tool sulla stessa \acs{GPU} usata per DeepSEA impiega 18 minuti, mentre, se allenato su un \textsl{MacBook 2.8-GHz Intel Core i7}, sono necessarie circa sei ore e mezza. DeepSATA, invece, non fornisce alcuna informazione sul modello di macchina utilizzato per l'allenamento o sul tempo impiegato, se non che è stato necessario limitare la dimensione dell'input a causa di vincoli di risorse.

In conclusione, vista la mancanza di informazioni complete da parte dei tre tool, in futuro si potrebbe effettuare un confronto sperimentale tra di essi, al fine di ottenere un paragone imparziale che fornisca in modo più dettagliato informazioni riguardanti la struttura, le richieste computazionali e le performance predittive dei tool.
