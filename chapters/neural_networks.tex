%!TEX root = ../main.tex

\chapter{Reti neurali}\label{chp:neural-networks}
% 
Il primo modello di intelligenza artificiale risale al 1943, dove E. McCulloch e W. Pitts cercarono di modellare un neurone come una semplice funzione predefinita. Nel modello, il neurone, generava un valore in output nel caso in cui le variabili booleane di input, una volta elaborate, superavano una soglia prestabilita\,\cite[``A logical calculus of the ideas immanent in nervous activity'']{mcculloch1943logical}. Poco dopo, nel 1950, Alan Turing, pubblicò un articolo che definiva una metodologia per testare l'intelligenza di un modello\,\cite[``Computing machinery and intelligence'']{turing2009computing}. Questo test — noto anche come \textsl{The imitation game} — consisteva nel valutare se una macchina potesse imitare l'intelligenza umana tabilendo così un obiettivo per il campo dell'intelligenza artificiale, termine che venne conianto per la prima volta nella conferenza di Dartmouth nel 1956.

Dopo due anni, nel 1958, lo psicologo F. Resenblatt introdusse il \textsl{percettrone} che, a differenza del modello del '43, processava input non booleani e disponeva di pesi per bilanciare l'output\,\cite[``The perceptron: a probabilistic model for information storage and organization in the brain.'']{rosenblatt1958perceptron}. Anche se il percettrone sarà alla base delle reti neurali artificiali moderne, nei dieci anni successivi alla pubblicazione dell'articolo, le aspettative iniziali non vennero soddisfatte. Nel 1968 venne pubblicato un libro il quale analizzava le prestazioni del percettrone e constatava le forti limitazioni del modello, come l'impossibilità di risolvere problemi non linearmente separabili\,\cite[``Perceptrons'']{minsky2017perceptrons}. In seguito ad un secondo articolo del 1973, dove si evidenziavano gli scarsi risultati ottenuti in paragone con le grandi aspettative, iniziò il \textsl{Primo Inverno dell'Intelligenza Artificiale} dove fino alla metà degli anni Ottanta molte organizzazioni governative smisero di finanziare la ricerca sull'Intelligenza Artificiale (\acs{AI}). L'Inverno della \acs{AI} terminò nel 1985 con l'introduzione del \textit{Gradient Descent Optimization}, algoritmo che permetteva di aggiornare i pesi in modo tale da minimizzare l'errore in una rete. Un anno dopo venne introdotto l'algoritmo della \textit{back-propagation}, fondamentale per lo sviluppo di reti neurali, costituite da più livelli di neuroni, ciascuno dei quali è collegato al livello successivo\,\cite[``Learning representations by back-propagating errors'']{rumelhart1986learning}.

Nonostante il grande sviluppo nella parte algoritmistica, l'hardware non era computazionalmente prestante da supportare le richieste di calcolo delle reti neurali artificiali. Questa carenza nella potenza di calcolo portò al \textsl{Secondo Inverno dell'Intelligenza Artificiale}, periodo in cui l'interesse scientifico si spostò su modelli che richiedevano meno potenza di calcolo, come le \textit{Support Vector Machines} introdotte nel 1963. Il Secondo Inverno della \acs{AI} terminò a metà degli anni Novanta quando il progresso dell'hardware riuscì a soddisfare i requisiti computazionali dei modelli basati su reti neurali. Il costante sviluppo culminò nell'ultimo ventennio quando venne introdotta la GPU, che, insieme all'aumento dei dati disponibili, accelerò notevolmente i progressi nel campo dell'\acs{AI}\,\cite{flasinski2016introduction, muthukrishnan2020brief}.

\section{Principi di base ed evoluzione}
%
Le reti neurali artificiali (\acs{ANN}) — comunemente note come reti neurali (\acs{NN}) — mirano a rappresentare un modello semplificato del cervello, trattato come una struttura composta da neuroni. Risulta quindi essenziale comprendere il funzionamento del singolo \textsl{neurone artificiale} per poi esplorare la struttura di una rete neurale, che è un collegamento tra più neuroni artificiali.

Come un neurone biologico, il neurone artificiale (Figura\,\ref{fig:artificial-neuron}) riceve un numero indefinito $n$ di segnali in \textsl{input}, che possono essere rappresentati con la notazione $x_0, x_1, \dots, x_n$. Tali valori possono essere raggruppato nel vettore di input $\mathbf{x} = \left[x_0, x_1, \dots, x_n\right]$. Per descrivere il risultato di tutti i segnali in ingresso del neurone, si introduce una funzione $g$, che si suppone essere una semplice somma algebrica dei segnali di input $x_i$, con $i\in[0,\,n]$. Ogni segnale di input, prima di essere sommato viene moltiplicato per il rispettivo peso (\textit{weight}) $w_i$, con $i\in[0,\,n]$, che appartiene al vettore dei pesi $\mathbf{w} = \left[w_0, w_1, \dots, w_n \right]$. Ne consegue che il segnale in uscita, indicato con $v$, comprenderà la somma del prodotto del segnale \textit{i}-esimo ($x_i$) con il rispettivo peso \textit{i}-esimo ($w_i$):
% 
\begin{gather*}
    v = g\left(\mathbf{w}, \mathbf{x}\right) = \sum_{i = 0}^n w_i\,x_i
\end{gather*}
% 
\begin{figure}[!b]
    \centering
    \input{assets/TikZ/artificial-neuron.tex}
    \caption[Rappresentazione schematica del funzionamento di un percettrone.]{Rappresentazione schematica del funzionamento di un percettrone. I segnali in input $X_i$ vengono moltiplicati con i rispettivi pesi $W_i$ e sommati tra loro; il risultato $v$ viene processato dalla funzione di $f(v)$ che restituisce l'output $z$.}\label{fig:artificial-neuron}
\end{figure}
% 
\noindent Per attivare un neurone, è necessario che il segnale $v$ prodotto in \textsl{output} sia superiore ad una soglia prescelta, solitamente rappresenta dalla prima componente del vettore di input ($x_0$). Questo valore, noto come \textit{bias}, è scelto arbitrariamente ma spesso viene impostato ad 1. Il criterio che descrive l'attivazione del neurone artificiale è riassunto nella \textsl{funzione di attivazione}, chiamata $z = f(v)$. La funzione di attivazione più semplice che descrive tale criterio la funzione \textsl{gradino} \textbf{1}$(v)$, descritta graficamente nella Figura\,\ref{fig:step-function}:
% 
\begin{gather*}
    z(v) = \text{\textbf{1}}(v) =
    \begin{cases}
        1 \hspace{20px} \text{se } v\geq0\\
        0 \hspace{20px} \text{se } v<0
    \end{cases}
\end{gather*}
% 
\begin{figure}[!b]
    \centering
    \input{assets/TikZ/step-function.tex}
    \caption[Grafico della funzione gradino \textsl{1}$(v)$.]{Grafico della funzione gradino \textbf{1}$(v)$. Si osserva che vale zero per valori strettamente minori di zero e uno per valori maggiori o ugali a zero.}\label{fig:step-function}
\end{figure}
% 
\noindent Come per un cervello umano, anche la rete neurale deve essere in grado di impararare. In particolare un neurone artificiale deve essere in grado di reagire in un determinato modo quando in input riceve determinati \textsl{pattern}. Affinchè il neurone sia in grado di comporatarsi correttamente di fronte a dei pattern, è fondamentale allenarlo: è dunque necessario utilizzare un \textit{training dataset} che contenga numerosi vettori di input $\mathbf{x}$ e, per ciascuno di essi sia presente la risposta corretta che il neurone dovrebbe fornire. Formalmente definiamo il dataset $\mathcal{D}$ come:
% 
\begin{gather*}
    \mathcal{D} = \left\{ \left\{ X_1,\, y_1 \right\},\,\left\{ X_2,\, y_2 \right\},\,\dots\,\left\{ X_j,\, y_j \right\},\,\dots\,\left\{ X_M,\, y_M \right\} \right\}  
\end{gather*}
% 
\noindent Il dataset\footnote{Un dataset così definito è utilizzato nel \textit{supervised learning}, dove all'interno del dataset sono presenti sia i vettori in ingresso che la risposta attesa. Si contrappone l'\textit{unsupervised learning} — che non verrà trattato — dove sono presenti solo i vettori in ingresso e sono sconosciute le risposte attese.} è composto da $M$ vettori di input, definiti con la notazione $X_j$ ($j\in[1,\,M$]), e da esattamente $M$ risposte $y_j$, che rappresentano il comportamento atteso del neurone se il vettore di ingresso è $X_j$. È quindi possibile definire la matrice $\mathbf{X}$ che contiene esattamente $M$ vettori — ciascuno in una riga — i quali sono composti esattamente da $n$ componenti (o \textit{feature}), che sono le componenti associate al vettore dei pesi $\mathbf{w}$, precedentemente introdotto. Alla matrice $\mathbf{X}$ è associato il vettore $\mathbf{y}$, anch'esso di dimensione $M$ tale per cui la componente $y_j$ sia la risposta attesa del vettore di input $X_j$.
% 
\begin{gather*}
    \begin{aligned}
        \mathbf{X} &= 
            \begin{bmatrix}
            X_1^0       & X_1^1         & \cdots     & X_1^i         & \cdots     & X_1^n     \\
            X_2^0       & X_2^1         & \cdots     & X_2^i         & \cdots     & X_2^n     \\
            \vdots      & \vdots        & \ddots     & \vdots        & \ddots     & \vdots    \\
            X_j^0       & X_j^1         & \cdots     & X_j^i         & \cdots     & X_j^n     \\
            \vdots      & \vdots        & \ddots     & \vdots        & \ddots     & \vdots    \\
            % X_{M-1}^0   & X_{M-1}^1     & \cdots     & X_{M-1}^i     & \cdots     & X_{M-1}^n \\
            X_M^0       & X_M^1         & \cdots     & X_M^i         & \cdots     & X_M^n     \\
            \end{bmatrix}
        %
        \hspace{60px}
        %
        \mathbf{y} = 
            \begin{bmatrix}
            y_1 \\ y_2 \\ \vdots \\ y_j \\ \vdots \\ y_M
            \end{bmatrix}
    \end{aligned}
\end{gather*}
% 
\noindent Da questo deriva che il vettore $X_j$ è dimensionalmente compatibile con il vettore di pesi $\mathbf{w}$ in quanto hanno esattamente la stessa dimensione.
% 
\begin{gather*}
    \begin{aligned}
        X_j = \left[ X_j^0,\, X_j^1,\,\dots,\, X_j^n \right]
        %
        \hspace{60px}
        %
        \mathbf{w} = \left[w_0,\, w_1,\, \dots,\, w_n \right]
    \end{aligned}
\end{gather*}
% 
\noindent Perciò il dataset $\mathcal{D}$ può essere riscritto attraverso la matrice $\mathbf{X}$ ed il vettore di risposte attese associato $\mathbf{y}$.
% 
\begin{gather*}
    \mathcal{D} = \left\{ \mathbf{X},\, \mathbf{y} \right\}  
\end{gather*}
% 
Con un dataset di partenza si può definire un algoritmo generico che sia in grado di descrivere il processo di apprendimento di neurone artificiale. Come descritto nell'Algoritmo\,\ref{alg:PLA}, dopo aver inizializzato il vettore di pesi $\mathbf{w}$, per ogni vettore $X_j$ del dataset $\mathcal{D}$ vengono calcolati il segnale $v$ e il valore della funzione di attivazione $z = f(v)$. L'idea alla base dell'algoritmo è quella di modificare il vettore di pesi $\mathbf{w}$ in funzione del risultato della funzione di attivazione rispetto al segnale processato.
% 
\begin{algorithm}[ht]
    \caption{Allenamento del neurone artificiale}\label{alg:PLA}
    \begin{algorithmic}
        \REQUIRE{Dataset $\mathcal{D}$}

        \STATE{Inizializza $\mathbf{w}$ con numeri casuali}
        \STATE$j \gets 1$
        
        \WHILE{$j \leq M$}
            \STATE\text{Calcola $v$ in funzione di $X_j$ e $\mathbf{w}$}
            \STATE\text{Determina $z$ in rapporto a $v$ e $y_j$}
            \STATE\text{Modifica $\mathbf{w}$ a seconda del risultato $z$}
            \STATE$j \gets j + 1$
        \ENDWHILE\,
    \end{algorithmic}
\end{algorithm}
% 
\noindent In questo modo, una volta processati tutti i vettori presenti nel dataset, è possibile constatare se il neurone sia stato in grado di apprendere il comportamento desiderato in funzione del vettore in ingresso.

Il modello di neurone artificiale che viene tuttora utilizzato nelle reti neurali è il percettrone. Dato un vettore in ingresso $X_j$ e un vettore di pesi $\mathbf{w}$, il segnale $v$ è dato dalla somma algebrica dei prodotti di ciascuna delle componenti:
% 
\begin{gather*}
    v = g\left(\mathbf{w}, X_j\right) = \sum_{i = 0}^n w_i\,X_j^i
\end{gather*}
% 
\noindent La funzione di attivazione $f(v)$ è la funzione \textsl{``segno''}\,(Figura\,\ref{fig:sign-function}), chiamata anche \textsl{gradino bipolare} e definita come segue. 
% 
\begin{figure}[!b]
    \centering
    \input{assets/TikZ/sign-function.tex}
    \caption[Grafico della funzione segno \textsl{sign}$(v)$.]{Grafico della funzione segno \textbf{sign}$(v)$. Si osserva che vale -1 per valori strettamente minori di zero e 1 per valori maggiori o ugali a zero.}\label{fig:sign-function}
\end{figure}
% 
\begin{gather*}
    z(v) = \text{\textbf{sign}}(v) =
    \begin{cases}
        1 \hspace{29px} \text{se } v\geq0\\
        -1 \hspace{20px} \text{se } v<0
    \end{cases}
\end{gather*}
% 
\noindent Il particolare più importante però è la \textit{learning rule}, ovvero il criterio secondo il quel il vettore di pesi è aggiornato a seconda della predizione del percettrone. Se la predizione $z_j$ rispetto al vettore $X_j$ è diversa dalla risposta attesa $y_j$, allora il vettore di pesi è modificato come segue.
% 
\begin{gather*}
    w_i \, = \, w_i \, + \, y_j\,X_j^i
\end{gather*}

\noindent



\section{Reti neurali convoluzionali}
% 

\section*{Capitolo 11 — Introduction to Artificial Intelligence}
% file:///C:/Users/Home/Desktop/Books/Introduction%20to%20Artificial%20Intelligence.pdf

\todo{vedi se inserire Adaline e Sigmoide}
\todo{Inserisci il disegnone di una rete neurale bella pimpante}

\begin{comment}
Per non diventare matti la notazione è l'opposta di quella sul file di Machine Learnign.
- ci sono esattamente N feature in un vettore di input, di conseguenza il vettore di pesi è di lunghezza N
- ci sono esattamente M vettori di input nel dataset, di conseguenza la lunghezza della label è M
- Il dataset D è composta da j colonne ed i righe
- Ciascuna riga j rappresenta un elemento del dataset
- Ciascuna colonna i rappresente un feature del dataset

Di conseguneza D_j indica il vettore j-esimo composto esattamente da N componenti. La label y_j indica il vero valore dell'input processato
\end{comment}





\,\cite{flasinski2016introduction}

\todo{parla anche delle metodologie di evaluation}
\todo{Vedi se nelle Reti Neurali vale la pena discutere la somiglianza con la \textsl{pattern recognition} (penso di no TBH)}
% Il modello di reti neurali può essere trattat come uni dei tre approcci di Pattern Recognition

\todo{convolution: filters sono di fatto dei profile sulle sequenze}

\begin{comment}
Il primo modello di intelligenza artificiale tento di creare il funzionamento di un neurone (ce la foto se vuoi metterla). I primi modelli piu semplici furono delle semplicit input-output function. IN seguito le funzioni divennero piu complicate, piu livelli furono aggiunti e feedback bidiriezionale fino ad arrivare ai modelli odierni di DL.

\@ La prima pubblicazione sulla \ac{AI}, fu del 43 (\cite{mcculloch1943logical}) che descrive un modello di computer che impara attraverso un processo paragonabile a quello dei neuroni: vengono quindi introdotti i neuroni MCP che prendono il nome dai due creatori (McCulloch and Pitts). Questo neuropne prendeva in input delle varibili booleane, processarle attraverso una funzione scelta a priori e poit, se il risultato superava una certa threshold, l'output avra un valore. Quyando la threshold è superata si diuce che il neurone si attiva. Aveva molte limitazioni, generava un output binario e richiedava un numero fisso di pesi.

Uno dei primi articoli che introducono una metodologia per testare l'intelligenza di un modello fu il testo di turing nel 1950. Questo test, chiamato Test di Turing, si domandava se una macchina fosse in grado di imitare l'intelligenza umana (\cite[Computing machinery and intelligence]{turing2009computing}). Il test prende in causa un interrogatore umano che fa la stessa domanda a due ascoltatori, una persona ed una macchina. Se l'interrogatopra non riesce a distingure l'uomo dalla macchina allora la macchina ha superato il test di Turing. Questo test è stato da sempre l'obiettivo dellàintelligenza artificiale anche se ad oggi alcuni dubbi stanno sorgendo. La conferenza del 1956 a Dartmouth (organizzata da Marvin Minsky, John McCarty, Claude Shannon e Nathan Rochester) è considerata il momento in cui l'\ac{AI} è stata globalmente riconosciuta. 

Un metodo piu sofisticato venne introdotto nerl 1958 da Resenblatt, chiamato percettrone il quale precessava input non booleani e pesi per bilanciare. Una funzione non lineare processa la somma dei prodotto degli input e dei pesi che rende il modell piu flessibile: questo sara la base per le reti neurali.

Il percettorne di Resenblatt aveva fatto molto clamore ma le aspettative dell'opinione pubblica non furoino incontrate. Le aspettative del pubblico non furono assolutamente incontrata, tanto che nel 68 un paper di Minsky e Papert dimostro le forte limitazioni del percettrone, dove di fatto veniva descritto che il percettrone non sarebbe stato in grado di emulare una operazione di or esclusivo con due input (non erano linearmente separabili). Nel 73 una seconda pubblicazione di Lighthill sottolinea le forti aspettativde del pubblico e gli scarsi risultati ottenuti dal progresso. Dal 74 all'80 ci fu il primo invero dell'intelligenza artificale dove essenzialmente nulla accadde e tutti persereo l'interesse al riogurado (controllo bene le fonto che qua me la sono un po inventata ecco letsgoski). 

Nel 1985 l'inverdo dell'ai fini quando venne introdotto il Gradent Descent Optimization per minimizzare l'errore in una rete (Rumelhart, Hinton and Williams). Inoltre nell 86 Rumelhart e colleghi espansero il lavoro introducento il conetto di back-propagation nelle reti neurali multilivello (molti livelli di neuroni attaxccati tra loro). QUersto algoritmo rivoluziono le capacita di imparare delle reti. Il secondo inverno dell \ac{AI} inizio negli anni 90, dove ci si rese conto che queste reti neurali non erano scalabili: cera troppa poca potenza di calcolo.

Questo inverno venne causato dalle aspettative sulle capacita delle reti neurali che pero non abdavanbo di paripasso con lo sviluppo della potenza computazionale. Per questo motivo i ricercatori si spostaro su altri alogirtimi, che richiedevano meno potenza di calcolo come le support evctor machines (1963, Vapnik and Chervonenkis). Quando quiesti algoritmi furono implementati in kernel non lineari nel 92 (kernl trick) si fu in grado di rsolvere iperpiano non lineari senza la necessita di requisiti computazionali elevati. 

Quando alla meta degli anni 90 la potenza computazionale crebbe, l'attenzione per la \ac{AI} auimeto di conseguenza. Nel 97, IBM sviluppo un super computer, chiamato Deep Blue, che sconfisse Kasparov a scacchi. Quersto evento rese le reti neurali risolrgere, con l'introduzioned elle reti nmeurali convoluzionali.

Nel 98 venne pubblicata LeNet-5, che è una rete convoluzionale a sette livelli. Viene usata la convoluzione per fare subsampling per poi passae ai livelli fully connected per predirre l'output. Anche in questo caso il modello era difficile da far scalare a causa di harder e data contstraints. Questo problema continuo fino all'ultimo decennio, dove due grandi avanzamente furono cruciali: lo storage dei dati e la GPU (graphical processing unit). I dati furono più accessibili e con meno costi. COn un alto livello di dati disponibili, la performance degli algoritmi di madhine learnign amutneto.

Questo introdusse il deeplearninng, nel 2006 sbloccando una performance eccellente nella speech recognition che prima era molto difficile. La nascita delle GPU introdusse una potenza di calcolo tale per cui si potevano introdurre livelli molto più complessi 
\end{comment}

\begin{comment}
Nel 1950 Alan turing pubbliuca ``Computing machinery and intewlligence'' dove viene introdotto il concetto di macchina intelligente. Viene introdotto anche il test di turing che è un test che determina se una mchhina e piu o meno capace di imitare l'uomo. Nel 1956, la onferenza di Darmont (c'è Shanno, Minsky che copnia il temrine intelligenza aertrifixcale). Gli obbbiettivi era quelli di machine translation. Rosenblat negli anni 60 si inveta il percettrone, rete neruale semplicissima. Agli anni 60 seguono due risultati allo stop dell IA, vhiamto inverno della intelligenza artificiazle. Minsky pubblica un libro, chiamato perceptrons dove viene dimostrato che il percettoprne èin grado di risolvere solo probleimi semplic, libnearmente seaprabili. Esce un report, Alpac, dove viene osservato che nemmeno la task di traduzione funziona.

Dagli anni 80, viene inventata la backpropagation dove le reti neurali diventano efficaci. Qui nascono anche i sistemi esperti, che sono dei sistemi che, per esempio, si basano su delle regole logiche: qualcosa dis uper dettagliato ed un esperto inietta dentro la sua conoscienza. Nel 1996/1997 Gary kasparov sfidas DeepBLUE, progettato da IBM.\@ La prima sfida, Kasparov vince il mach overall ma perde due partite. Nella seconda edizione del 97, deepBLUE vince tutto. Per la prima volta, un esperto viene sconmfitto da una macchina. Negli anni 2000 arriva il machine learning: apprendimento automatico. Una macchina che apprende dai dati.  Reti neurali sono un sottoinsieme del ML, il deep learning sono un sottinsieme di rete neruale (LLM sono un soittinseeme di deep NN). 
\end{comment}


